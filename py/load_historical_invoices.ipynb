{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import awswrangler as awr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pegando excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\relatorio_inadimplencia\\historico_faturas.xlsx\"\n",
    "\n",
    "df_base = pd.read_excel(excel_path, engine='openpyxl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajustes pontuais base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_comuns = [\n",
    "    \"matricula\",\n",
    "    \"conjunto\",\n",
    "    \"cooperativa\",\n",
    "    \"ponteiro\",\n",
    "    \"numero_boleto\",\n",
    "    \"nosso_numero\",\n",
    "    \"unidade\",\n",
    "    \"associado\",\n",
    "    \"data_vencimento\",\n",
    "    \"data_baixa\",\n",
    "    \"valor_titulo\",\n",
    "    \"valor_baixa\",\n",
    "    \"data_emissao\",\n",
    "    \"data_atualizacao\",\n",
    "    \"situacao\"\n",
    "]\n",
    "\n",
    "df_base = df_base[colunas_comuns]\n",
    "df_base.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa','ponteiro', 'situacao', 'data_atualizacao'], inplace=True)\n",
    "df_base.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa','ponteiro', 'data_atualizacao'], inplace=True)\n",
    "\n",
    "df_base['data_vencimento'] = pd.to_datetime(df_base['data_vencimento'])\n",
    "df_base['data_vencimento'] = df_base['data_vencimento'].dt.date \n",
    "\n",
    "df_base['data_baixa'] = pd.to_datetime(df_base['data_baixa'])\n",
    "df_base['data_baixa'] = df_base['data_baixa'].dt.date \n",
    "\n",
    "df_base['data_emissao'] = pd.to_datetime(df_base['data_emissao'])\n",
    "df_base['data_emissao'] = df_base['data_emissao'].dt.date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tratando colunas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base['data_baixa'] = df_base['data_baixa'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_base['data_emissao'] = df_base['data_emissao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_base['data_vencimento'] = df_base['data_vencimento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_base['valor_titulo'] = df_base['valor_titulo'].fillna(0)\n",
    "df_base['valor_baixa'] = df_base['valor_baixa'].fillna(0)\n",
    "df_base['nosso_numero'] = df_base['nosso_numero'].fillna('NULL')\n",
    "df_base['numero_boleto'] = df_base['numero_boleto'].fillna('NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gerando base de inadimplência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\relatorio_inadimplencia\\sql\\faturas_inadimplentes.sql\"\n",
    "\n",
    "with open(query_path, 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "df_inadimplentes = awr.athena.read_sql_query(query, database='silver')\n",
    "df_inadimplentes = df_inadimplentes.drop_duplicates('ponteiro', keep='first')\n",
    "\n",
    "df_inadimplentes.loc[:, 'data_atualizacao'] = df_inadimplentes['data_vencimento']\n",
    "df_inadimplentes.loc[:, 'situacao']='INADIMPLENTE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecionando limite base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.to_datetime('today').date()\n",
    "year = today.year\n",
    "month = today.month\n",
    "df_inadimplentes['data_vencimento'] = pd.to_datetime(df_inadimplentes['data_vencimento'])\n",
    "\n",
    "\n",
    "df_inadimplentes = df_inadimplentes[df_inadimplentes['data_vencimento']> pd.to_datetime('2025-05-31')]\n",
    "#df_inadimplentes = df_inadimplentes[df_inadimplentes['data_vencimento'].dt.month == month]\n",
    "\n",
    "#df_inadimplentes = df_inadimplentes[df_inadimplentes['data_vencimento'].dt.year == year]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tratando colunas df_inadimplentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in colunas_comuns:\n",
    "    if col not in df_inadimplentes.columns:\n",
    "        df_inadimplentes.loc[:, col] = pd.NA\n",
    "\n",
    "df_inadimplentes = df_inadimplentes[colunas_comuns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenando e removendo linhas inteiras duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_16900\\3111717009.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_composto_inadimplentes =  pd.concat([df_base, df_inadimplentes])\n"
     ]
    }
   ],
   "source": [
    "df_composto_inadimplentes =  pd.concat([df_base, df_inadimplentes])\n",
    "df_composto_inadimplentes = df_composto_inadimplentes.drop_duplicates(keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criando listra que filtra apenas os ponteiros de inadimplentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_composto_inadimplentes['data_vencimento'] = pd.to_datetime(df_composto_inadimplentes['data_vencimento'])\n",
    "#df_composto_inadimplentes_mes = df_composto_inadimplentes[df_composto_inadimplentes['data_vencimento'].dt.month == month]\n",
    "#df_composto_inadimplentes_mes = df_composto_inadimplentes[df_composto_inadimplentes['data_vencimento'].dt.year == year]\n",
    "\n",
    "df_inadimplentes_lista = df_composto_inadimplentes.loc[df_composto_inadimplentes['data_vencimento'].notna() ,'ponteiro'].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gerando o relatório de pagamentos do mês e tratando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\relatorio_inadimplencia\\sql\\faturas_baixadas.sql\"\n",
    "\n",
    "with open(query_path, 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "df_pagamentos = awr.athena.read_sql_query(query, database='silver')\n",
    "\n",
    "\n",
    "for col in colunas_comuns:\n",
    "    if col not in df_pagamentos.columns:\n",
    "        df_pagamentos.loc[:, col] = pd.NA\n",
    "df_pagamentos = df_pagamentos[colunas_comuns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tratando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pagamentos.loc[:, 'data_atualizacao'] = df_pagamentos['data_baixa']\n",
    "df_pagamentos.loc[:, 'situacao']='PAGO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_pagamentos['data_baixa'] = pd.to_datetime(df_pagamentos['data_baixa'])\n",
    "df_pagamentos['data_vencimento'] = pd.to_datetime(df_pagamentos['data_vencimento'])\n",
    "\n",
    "df_pagamentos = df_pagamentos.drop_duplicates('ponteiro', keep='first')\n",
    "df_pagamentos = df_pagamentos[\n",
    "    (df_pagamentos['data_baixa']> pd.to_datetime('2025-05-31'))&\n",
    "    (df_pagamentos['data_vencimento']> pd.to_datetime('2025-05-31'))\n",
    "    ]\n",
    "#df_pagamentos = df_pagamentos[df_pagamentos['data_baixa'].dt.month == month]\n",
    "#df_pagamentos = df_pagamentos[df_pagamentos['data_baixa'].dt.year == year]\n",
    "\n",
    "df_pagamentos_inadimplencia = df_pagamentos[df_pagamentos['ponteiro'].isin(df_inadimplentes_lista)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenando faturas baixadas dos vencidos deste mes com a base composta e atualizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.almeida\\AppData\\Local\\Temp\\ipykernel_16900\\3147402727.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_atualizado = pd.concat([df_composto_inadimplentes, df_pagamentos_inadimplencia])\n"
     ]
    }
   ],
   "source": [
    "df_atualizado = pd.concat([df_composto_inadimplentes, df_pagamentos_inadimplencia])\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'situacao', 'data_atualizacao'], inplace=True) #eliminando faturas duplicadas\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'data_atualizacao'], inplace=True) #eliminando faturas que tenham a mesma data e identificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajustando formatação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_atualizado['data_vencimento'] = pd.to_datetime(df_atualizado['data_vencimento'])\n",
    "df_atualizado['data_vencimento'] = df_atualizado['data_vencimento'].dt.date \n",
    "\n",
    "df_atualizado['data_baixa'] = pd.to_datetime(df_atualizado['data_baixa'])\n",
    "df_atualizado['data_baixa'] = df_atualizado['data_baixa'].dt.date \n",
    "\n",
    "df_atualizado['data_emissao'] = pd.to_datetime(df_atualizado['data_emissao'])\n",
    "df_atualizado['data_emissao'] = df_atualizado['data_emissao'].dt.date \n",
    "\n",
    "df_atualizado['data_atualizacao'] = pd.to_datetime(df_atualizado['data_atualizacao']).dt.date\n",
    "\n",
    "df_atualizado = df_atualizado[colunas_comuns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tratando colunas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado['data_baixa'] = df_atualizado['data_baixa'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_atualizado['data_vencimento'] = df_atualizado['data_vencimento'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_atualizado['data_emissao'] = df_atualizado['data_emissao'].fillna(pd.Timestamp('1900-01-01'))\n",
    "df_atualizado['valor_titulo'] = df_atualizado['valor_titulo'].fillna(0)\n",
    "df_atualizado['valor_baixa'] = df_atualizado['valor_baixa'].fillna(0)\n",
    "df_atualizado['nosso_numero'] = df_atualizado['nosso_numero'].fillna('NULL')\n",
    "df_atualizado['numero_boleto'] = df_atualizado['numero_boleto'].fillna('NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retornando ao excel base atualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atualizado['data_emissao'] = pd.to_datetime(df_atualizado['data_emissao'], errors='coerce')\n",
    "df_atualizado['data_emissao'] = df_atualizado['data_emissao'].dt.date\n",
    "\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'situacao', 'data_atualizacao'], inplace=True) #eliminando faturas duplicadas\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'data_atualizacao'], inplace=True) #eliminando faturas que tenham a mesma data e identificação\n",
    "\n",
    "excel_save_path = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\relatorio_inadimplencia\\historico_faturas.xlsx\"\n",
    "df_atualizado.to_excel(excel_save_path, engine='openpyxl', index=False, sheet_name='historico_faturas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3571"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_atualizado)\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'situacao', 'data_atualizacao'], inplace=True) #eliminando faturas duplicadas\n",
    "df_atualizado.drop_duplicates(subset=['matricula', 'conjunto', 'cooperativa', 'ponteiro', 'data_atualizacao'], inplace=True) #eliminando faturas que tenham a mesma data e identificação\n",
    "len(df_atualizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path1 = r\"C:\\Users\\raphael.almeida\\Documents\\Processos\\relatorio_inadimplencia\\teste.xlsx\"\n",
    "#df_atualizado.to_excel(path1, engine='openpyxl',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
